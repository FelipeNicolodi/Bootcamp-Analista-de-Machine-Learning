{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "desafio_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3_ugmhLc0s2",
        "colab_type": "text"
      },
      "source": [
        "## Desafio - Módulo 3 - Machine Learning\n",
        "##### **Com respotas do questionário**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbwJWsiNMY9b",
        "colab_type": "text"
      },
      "source": [
        "## Objetivo:\n",
        "* Análise exploratória dos dados (EDA - Exploratory Data Analysis).\n",
        "* Preparação dos dados.\n",
        "* Comparação e ajuste de modelos de classificação.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMktEpbWcpP2",
        "colab_type": "text"
      },
      "source": [
        "Dataset: http://yann.lecun.com/exdb/mnist/ </br>\n",
        "Imagens: https://web.archive.org/web/20180628145339/http://blog.welcomege.com/mnist-database/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwj3Bnu2dXRK",
        "colab_type": "text"
      },
      "source": [
        "**The MNIST Database**<br>\n",
        "Description\n",
        "\n",
        "MNIST database, (modified national institute of standards of technology database) is a collection of handwritten 0-9 digit images. It contains training, test and validation dataset, and is a commonly used dataset to train and validate varied image processing and machine learning algorithms.\n",
        "\n",
        "In the previous post of logistic regression, neural network and TensorFlow introduction, I used a simple {y | x1, x2} dataset. Before my convolution neural network post, I will first introduce the MNIST database.\n",
        "\n",
        "The database contains 55,000 images in training, 10,000 in test, and 5,000 in validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17P_QEF63pH0",
        "colab_type": "text"
      },
      "source": [
        "## Questionário"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0TZOhmxm9Sl",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 1\n",
        "Qual(is) métrica(s) de qualidade você considera a(s) mais importante(s) para medir o desempenho do seu algoritmo de classificação?\n",
        "\n",
        "- Somente Acurácia.\n",
        "\n",
        "- ***Precisão ou F-Score.***\n",
        "\n",
        "- Perda de Hamming.\n",
        "\n",
        "- Perda 0-1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dysYObC_7SJL",
        "colab_type": "text"
      },
      "source": [
        "- Acurácia: quantos elementos foram corretamente classificadas.\n",
        "- Precisão: quantos elementos classificados positivos realmente são positivos.\n",
        "- F-Score: Recall e Precisão igualmente importantes!\n",
        "- Recall: quantos elementos positivos foram percebidos?\n",
        "- Perda de Hamming - Quantas labels erradas?\n",
        "- Perda 0-1 - Ou todas as labels dos elementos certas ou nada feito!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7RO38DoBTgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fonte: https://towardsdatascience.com/improving-accuracy-on-mnist-using-data-augmentation-b5c38eb5a903\n",
        "\n",
        "# importando as bibliotecas\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve85uwGW8xvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetching MNIST Dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "\n",
        "# Get the data and target\n",
        "X, y = mnist['data'], mnist['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hv7Od5C-IW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the train and test set\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dY0gqn-MqIb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3329901-f019-42c3-a164-7756d68e1c39"
      },
      "source": [
        "print(f'X_train: {len(X_train)} X_test: {len(X_test)} y_train: {len(y_train)} y_test: {len(y_test)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: 60000 X_test: 10000 y_train: 60000 y_test: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcy_IkRz-K5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "29060f73-b599-4963-aaef-39ef9a9a93ff"
      },
      "source": [
        "# Training on the existing dataset\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i9Ge4t8-szb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the model\n",
        "y_pred = rf_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ENqXkcgBHiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f8e1491d-7fc7-4e26-ec80-20f3c7590737"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, hamming_loss, zero_one_loss\n",
        "\n",
        "print('Acurácia        : ',accuracy_score(y_test, y_pred))\n",
        "print('Precisão        : ',precision_score(y_test, y_pred, average='micro')) \n",
        "print('F1-Score        : ',f1_score(y_test, y_pred, average='micro'))     \n",
        "print('Recall          : ',recall_score(y_test, y_pred, average='micro')) \n",
        "print('Perda de Hamming: ',hamming_loss(y_test, y_pred))\n",
        "print('Perda 0-1       : ', zero_one_loss(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia        :  0.9705\n",
            "Precisão        :  0.9705\n",
            "F1-Score        :  0.9705\n",
            "Recall          :  0.9705\n",
            "Perda de Hamming:  0.0295\n",
            "Perda 0-1       :  0.02949999999999997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HpNTK2ISXIR",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 2\n",
        "Suponha que seu contratante lhe deu 5000 exemplos de números que seu programa terá que classificar. Os exemplos, no entanto, não foram classificados previamente. Que tipo de algoritmo você usaria para gerar um modelo para essa base de dados?\n",
        "\n",
        "- ***Agrupamento***\n",
        "\n",
        "- Classificação multi label\n",
        "\n",
        "- Regressão\n",
        "\n",
        "- Classificação single label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exq_qkvcSEnK",
        "colab_type": "text"
      },
      "source": [
        "- Agrupamento - um cluster é uma coleção de objetos de dados previamente classificado que são similares dentro de um mesmo grupo (cluster) e são dissimilares entre clusters distintos.\n",
        "\n",
        "- Classificação multi label - são como uma extensão dos algoritmos de classificação binários, que, usualmente, determinam se o objeto sob análise pertence ou não pertence a uma classe específica.\n",
        "\n",
        "- Regressão - é utilizada para criar um algoritmo que faça previsões com valores numéricos. A intenção é estimar relacionamentos entre variáveis\n",
        "\n",
        "- Classificação single label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-AP8HvXNj48",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 3\n",
        "Suponha que você gerou uma curva de validação para testar o desempenho do seu algoritmo. Na curva, você comparou o desempenho do seu modelo com o desempenho do algoritmo na validação cruzada. O resultado exibiu a sua curva acima da curva da validação cruzada, ou seja, com desempenho bem melhor, e as curvas não convergiram. O que isso significa?\n",
        "\n",
        "- Baixa variância\n",
        "\n",
        "- ***Overfitting***\n",
        "\n",
        "- O modelo está bom para ir para produção\n",
        "\n",
        "- Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjFq3d_xNlZC",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 4\n",
        "Para este tipo de problema, seu contratante te diz, é preferível que o algoritmo “erre sempre da mesma maneira” do que ele “erre de maneira errática”. Isso se dá porque, na etapa de conferência manual dos resultados incorretos, erros “previsíveis” são corrigidos  de forma mais barata. Que característica seria desejável seu algoritmo ter para que ele tivesse esse tipo de comportamento?\n",
        "\n",
        "- Baixa tendência e baixa variância\n",
        "\n",
        "- Baixa tendência e alta variância\n",
        "\n",
        "- Alta tendência e alta variância\n",
        "\n",
        "- ***Alta tendência e baixa variância***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAAqhnCeNmXy",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 5\n",
        "Suponha que, após um ano com o seu algoritmo em execução, você perceba que os valores dos cheques tendem a ter magnitudes diferentes em diferentes épocas do ano. No final do ano, por exemplo, o normal é a maior parte dos cheques ter seis ou oito dígitos, considerando os centavos, enquanto no meio do ano a quantidade de dígitos é um tanto menor. Se você souber dessa tendência com antecedência, sua empresa poderá ajustar a etapa de conferência manual de dígitos errados, gerando economia de custos.\n",
        "\n",
        "Assim, você coleta dados de “quantidade média de dígitos nos valores dos cheques” por “mês/ano”. Que técnica de aprendizado de máquina você usaria para tentar analisar esse comportamento e fazer previsões acerca dos meses futuros?\n",
        "\n",
        "- ***Erro mediano absoluto.***\n",
        "\n",
        "- Acurácia.\n",
        "\n",
        "- Erro médio quadrático.\n",
        "\n",
        "- F-Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2fzT8NXNnmq",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 6\n",
        "Suponha que seu cliente te enviou 2100 números classificados previamente para alimentar o treino dos eu algoritmo. Você gera seu modelo. Um tempo depois, seu cliente pergunta se você precisa de mais dados. A obtenção desses dados acarretará em custos maiores, portanto não deve ser feita a não ser que vá trazer benefícios reais para seu algoritmo. Como você poderia descobrir se vale a pena trazer mais dados para o seu algoritmo?\n",
        "\n",
        "- Usando otimização de hiperparâmetros\n",
        "\n",
        "- ***Usando curvas de aprendizado***\n",
        "\n",
        "- Usando validação cruzada\n",
        "\n",
        "- Nenhuma alternativa é a correta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_pGADh-NoZj",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 7\n",
        "A técnica de validação cruzada “deixar P elementos de fora”, para o problema sob análise, seria uma boa escolha? Justifique sua resposta.\n",
        "\n",
        "- Não - ela não trará resultados melhores que a K-Grupos.\n",
        "\n",
        "- Sim - ela é a mais adequada para modelos de classificação\n",
        "\n",
        "- Sim - ela é a mais precisa e, portanto, vai nos dar maior confiabilidade\n",
        "\n",
        "- ***Não - ela é computacionalmente cara demais para ser viável***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZOeI04_NpaS",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 8\n",
        "Suponha que, num agrupamento, para aquele conjunto de dados, o retorno teve-se valor elevado de entropia. O que isso melhor quer dizer em relação às imagens usadas no treino?\n",
        "\n",
        "- Precisamos, necessariamente, de mais imagens.\n",
        "\n",
        "- O modelo está com desempenho inaceitável para as imagens escolhidas\n",
        "\n",
        "- As imagens estão bem separadas e o modelo está bom para ir para produção\n",
        "\n",
        "- ***As imagens estão se confundido umas com a outras. 1 com 7, por exemplo.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEWLFDI0NqEJ",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 9\n",
        "Suponha que você tenha usado um classificador multilabel para resolver o seu problema. Marque a alternativa CORRETA.\n",
        "\n",
        "- A perda de hamming é a métrica de qualidade mais adequada aqui.\n",
        "\n",
        "- Ambas a perda 0-1 e a perda de hamming são igualmente adequadas para resolver o problema.\n",
        "\n",
        "- ***A perda 0-1 é a métrica de qualidade mais adequada aqui.***\n",
        "\n",
        "- Não é possível modelar o problema como um classificador multilabel, pois só há dois resultados possíveis: cheque correto (positivo) e cheque errado (negativo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuKrcqJaNqv5",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 10\n",
        "Qual técnica de validação cruzada você usaria para resolver o seu problema?\n",
        "\n",
        "- A divisão de treino e teste - a perda de dados é aceitável para esse problema\n",
        "\n",
        "- ***A validação cruzada em k-grupos - é boa mas não é tão cara computacionalmente***\n",
        "\n",
        "- A divisão de treino e teste - nessa escala de problema, é a única viável\n",
        "\n",
        "- Deixar P elementos de fora - ela é a mais precisa e, portanto, vai nos dar maior confiabilidade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS8VbtaUNrky",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 11\n",
        "Considere a seguinte matriz de confusão de um teste para as classificações dos números 1 a 4. São 300 exemplos de cada número.\n",
        "\n",
        "![des-m0d3-01](https://drive.google.com/uc?id=1Sj-eLOFPe0tz9WhRCKMKz719_VT7xQRN)\n",
        "\n",
        "Calcule a acurácia para cada número\n",
        "\n",
        "\n",
        "- ***Para 1 a 4, respectivamente, 0.9084, 0.758, 0.817, 0.834***\n",
        "\n",
        "- Para 1 a 4, respectivamente, 0.758, 0.912, 0.817, 0.834\n",
        "\n",
        "- Para 1 a 4, respectivamente, 0.834, 0.758, 0.817, 0.9084\n",
        "\n",
        "- Para 1 a 4, respectivamente, 0.9584, 0.758, 0.723, 0.814"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekAoBwfuNsZZ",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 12\n",
        "Considere a seguinte matriz de confusão de um teste para as classificações dos números 1 a 4. São 300 exemplos de cada número.\n",
        "\n",
        "![des-m0d3-02](https://drive.google.com/uc?id=1Sj-eLOFPe0tz9WhRCKMKz719_VT7xQRN)\n",
        "\n",
        "Calcule a precisão para cada número.\n",
        "\n",
        "\n",
        "- ***Para 1 a 4, respectivamente, 0.85, 0.42, 0.625, 0.656***\n",
        "\n",
        "- Para 1 a 4, respectivamente, 0.80, 0.52, 0.625, 0.86\n",
        "\n",
        "- Para 1 a 4, respectivamente, 0.85, 0.52, 0.625, 0.656\n",
        "\n",
        "- Para 1 a 4, respectivamente, 0.80, 0.42, 0.625, 0.86"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeTZIy6lNtIQ",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 13\n",
        "Considere a seguinte matriz de confusão de um teste para as classificações dos números 1 a 4. São 300 exemplos de cada número.\n",
        "\n",
        "![des-m0d3-03](https://drive.google.com/uc?id=1Sj-eLOFPe0tz9WhRCKMKz719_VT7xQRN)\n",
        "\n",
        "Calcule o recall para cada número.\n",
        "\n",
        "\n",
        "- Para 1 a 4, 0.72, 0.50, 0.66, 0.70\n",
        "\n",
        "- Para 1 a 4, 0.72, 0.55, 0.66, 0.60\n",
        "\n",
        "- Para 1 a 4, 0.77, 0.55, 0.66, 0.60\n",
        "\n",
        "- ***Para 1 a 4, 0.77, 0.50, 0.66, 0.70***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U2ai98vNuEJ",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 14\n",
        "Na técnica de validação cruzada “divisão 70-30”:\n",
        "\n",
        "- ***Não há regra sobre qual proporção dos dados devem ir para treino e teste.***\n",
        "\n",
        "- Nenhuma das alternativas está correta.\n",
        "\n",
        "- A divisão dos dados deve ser, sempre, 30% para treino e 70% para teste.\n",
        "\n",
        "- A divisão dos dados deve ser, sempre, 70% para treino e 30% para teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBH9MEPLNuyk",
        "colab_type": "text"
      },
      "source": [
        "#### Pergunta 15\n",
        "O problema descrito melhor se classifica como um problema de…\n",
        "\n",
        "- Classificação multi label.\n",
        "\n",
        "- Classificação single label.\n",
        "\n",
        "- Regressão.\n",
        "\n",
        "- ***Classificação single ou multi label, a depender da modelagem.***"
      ]
    }
  ]
}